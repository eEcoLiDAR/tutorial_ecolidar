{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lidar pointcloud analysis using laserchicken\n",
    "\n",
    "In this tutorial, we demonstrate an example of analysing AHN3 pointcloud data using the `laserchicken` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "AHN (Actueel Hoogtebestand Nederland) is a digtal height dataset of the Netherlands, measured with laser altimetry. The [AHN3](https://www.pdok.nl/introductie/-/article/actueel-hoogtebestand-nederland-ahn3-) dataset, which is used in this tutorial, is the third update of this dataset. \n",
    "\n",
    "AHN3 is a public dataset and is free from copyright restrictions. Please refer to [this link](https://data.overheid.nl/en/dataset/11513-actueel-hoogtebestand-nederland-3--ahn3-) for the license status of AHN3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import laserchicken as lc\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid the code duplication, we will write a small function `visualize_pc` to visualize the pointcloud later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pc(pc, col, npmax=None, clabel=None, pointsize=3):\n",
    "    \"\"\"\n",
    "    pc: input pointcloud\n",
    "    col: data column to be visualized\n",
    "    npmax: max number of points to visualize\n",
    "    clable: colorbar lable\n",
    "    pointsize: visualized point size \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    npoints = pc['vertex']['x']['data'].shape[0]\n",
    "    x, y, data = lc.utils.get_features(pc, ['x', 'y', col])\n",
    "    if npmax is not None:\n",
    "        if npoints>npmax: # vilsualize up to npmax points\n",
    "            idx=np.random.choice(range(npoints),npmax)\n",
    "            x = x[idx]\n",
    "            y = y[idx]\n",
    "            data = data[idx]\n",
    "    sc = ax.scatter(x, y, c = data, s = pointsize)\n",
    "    ax.grid()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_xlabel('RD x [m]')\n",
    "    ax.set_ylabel('RD y [m]')\n",
    "    fig.colorbar(sc, label=clabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data loading\n",
    "\n",
    "After the preparation job, we can start the data analysis with laserchicken. \n",
    "\n",
    "First we will use the `load` function to load in the raw pointcloud data stored in `AHN.las`. Note that apart from `.las`, the `load` function also support `.laz` and `.ply` format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from laserchicken import load\n",
    "pc = lc.load('../data/AHN3.las')\n",
    "z, = lc.utils.get_features(pc, ['z'])\n",
    "print(\"Loaded features: {}\".format(pc['vertex'].keys()))\n",
    "print(\"Total number of points: {}\".format(z.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also choose to only load the selected features. E.g., only load the coordinates of the points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_simple = lc.load('../data/AHN3.las', attributes = ['x', 'y', 'z'])\n",
    "z, = lc.utils.get_features(pc_simple, ['z'])\n",
    "print(\"Loaded features: {}\".format(pc_simple['vertex'].keys()))\n",
    "print(\"Total number of points: {}\".format(z.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a general overview of the point cloud, we can visualize the height for point of the points. Since 394473 is really a huge number of point, we will visualize 20000 points of the entire number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pc(pc, col='z', clabel='Height', npmax = 40000) # only visualize 40000 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: height normalization\n",
    "\n",
    "AHN3 uses a absolute height reference system. However, we are more interested in the height of the points relative to the local ground. Therefore, a height normalization process is applied to remove the topography from the height. We can use the `normalize` function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserchicken.normalize import normalize\n",
    "pc = normalize(pc)\n",
    "\n",
    "# Investigate the height vs normalized height\n",
    "height, height_norm = lc.utils.get_features(pc, ['z', 'normalized_height'])\n",
    "print(\"Height range: {} - {}, mean: {}\".format(height.min(), height.max(), height.mean()))\n",
    "print(\"Normalized height range: {} - {}, mean: {}\".format(height_norm.min(), height_norm.max(), height_norm.mean()))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(height, bins=20)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(height_norm, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no extra argument is specified, the `normalize` function uses the miminum height in the point cloud as a reference height, and re-refence all points to this height. This can be told from the range change and mean change we just printed out: the mean height change equals the miminum original height. Besides, the normalized height historgram only shifted to right comparing to the original height histogram, but there is no distribution change.\n",
    "\n",
    "The `normalize` height also supports local height normalization. This can be done by specifying the `cell_size` argument. If `cell_size` is given, a temporary grid of `cell_size` x `cell_size` (in meters) will be spanned over the full point cloud area. All points will be referenced to the minimum height within each cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height normalization within each 5x5m grid cell \n",
    "pc = normalize(pc, cell_size=5)\n",
    "\n",
    "# Investigate the height vs normalized height\n",
    "height, height_norm = lc.utils.get_features(pc, ['z', 'normalized_height'])\n",
    "print(\"Height range: {} - {}, mean: {}\".format(height.min(), height.max(), height.mean()))\n",
    "print(\"Normalized height range: {} - {}, mean: {}\".format(height_norm.min(), height_norm.max(), height_norm.mean()))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(height, bins=20)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(height_norm, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, when normalizing within each grid cell, the distribution of the normalized height also changed, instead of a single shift. We can also visualized the normalized height:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pc(pc, col='z', clabel='Height', npmax = 40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new attribute `normalized_height` will be added to the point cloud. We can compare the height range before and after normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, = lc.utils.get_features(pc, ['z'])\n",
    "height_norm, = lc.utils.get_features(pc, ['normalized_height'])\n",
    "print(\"Height range: {} - {}\".format(height.min(), height.max()))\n",
    "print(\"Normalized height range: {} - {}\".format(height_norm.min(), height_norm.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: data filtering\n",
    "\n",
    "Data filtering may be applied to zoom into a certain subset of the point cloud we are interested in. In `laserchicken`, it's possible to fileter the point cloud spatially, or based on value range of a certain attribute.\n",
    "\n",
    "To apply spatial filter on the data, one can use the `select_polygon` function with a predefined polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserchicken.filter import select_polygon\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Define a croping\n",
    "west = 88610\n",
    "east = 88690\n",
    "south = 458500\n",
    "north = 458580\n",
    "polygon = Polygon.from_bounds(east, south, west, north)\n",
    "\n",
    "pc_crop = select_polygon(pc, polygon.wkt)\n",
    "visualize_pc(pc_crop, col='z', clabel='Height', npmax=40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To filter data based on attribute value, there are three selection functions: `select_above`, `select_below` and `select_equal`. For example, we know the height reference point has normalized_height=0, we can find that point by `select_equal`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserchicken.filter import select_equal\n",
    "\n",
    "# Select height reference point, which has the 'normalized_height' equal to zero\n",
    "p_ref = select_equal(pc, 'normalized_height', 0)\n",
    "xref, yref, zref = lc.utils.get_features(p_ref, ['x', 'y', 'normalized_height'])\n",
    "print(\"Coordinates (x, y, norm_height) of the reference points: ({}, {}, {})\".format(xref[0], yref[0], zref[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `select_above` and `select_below` to separate the groud point and the non ground points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserchicken.filter import select_above, select_below\n",
    "\n",
    "# Assume all points with normalized height below the threshold should be ground points.\n",
    "height_thres = 0.5 \n",
    "\n",
    "# Filtering\n",
    "pc_ground = select_below(pc, 'normalized_height', height_thres)\n",
    "pc_non_ground = select_above(pc, 'normalized_height', height_thres)\n",
    "\n",
    "# Inspection\n",
    "nh_ground, = lc.utils.get_features(pc_ground, ['normalized_height'])\n",
    "nh_non_ground, = lc.utils.get_features(pc_non_ground, ['normalized_height'])\n",
    "print(\"Groud points norm-height range: {} - {}\".format(nh_ground.min(), nh_ground.max()))\n",
    "print(\"Non groud points norm-height range: {} - {}\".format(nh_non_ground.min(), nh_non_ground.max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In later processing we will use `pc_non_ground`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: feature extraction\n",
    "\n",
    "For a better understading of the poincloud, we need to investigate the common characters of multiple points within a certain range. \n",
    "\n",
    "To do this, we devide the poincloud into volumes. Within each volume, various statistics are computed to represent the volume. These statistics are referred as \"features\". In each volume, the derived features are assigned to an artificial point representing the volume, which is referred as the \"target point\".  \n",
    "\n",
    "We can first check what are the build-in features in `laserchicken`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserchicken.feature_extractor.feature_extraction import list_feature_names\n",
    "sorted(list_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One option to create target points is to define the a homogeneous grid, and create one target point within each grid. \n",
    "\n",
    "Here we first define the grid, then use `laserchicken.utils.create_point_cloud` to create target points with given coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolution of the target pointcloud, in meter\n",
    "resolution = 2\n",
    "\n",
    "# Define the grid system \n",
    "pcx, pcy = lc.utils.get_features(pc_non_ground, ['x', 'y'])\n",
    "x = np.arange(pcx.min(), pcx.max(), resolution) + resolution/2.\n",
    "y = np.arange(pcy.min(), pcy.max(), resolution) + resolution/2.\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "# Create target points:\n",
    "targets = lc.utils.create_point_cloud(x = xv.flatten(),\n",
    "                            y = yv.flatten(),\n",
    "                            z = np.zeros_like(xv.flatten()))\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the target pointcloud is made, the statistics will be aggregated to the target point. The aggregation per target point is performed with a given searching volume, which has a customizable shape and size. Here we use the \"cell\" volume with the size of target pointcloud resolution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserchicken import build_volume\n",
    "\n",
    "volume = build_volume(\"cell\", side_length=resolution)\n",
    "volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per target point, we first find the neighboring points from the orihinal point cloud within the given aggragation volum. Then we compute the statistics of interest. Here we compute the \"mean normalized height\", which will be added as a feature to the target pointcloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserchicken import compute_neighborhoods, compute_features\n",
    "\n",
    "neighborhoods = compute_neighborhoods(pc_non_ground, targets, volume)\n",
    "compute_features(pc_non_ground, neighborhoods, targets, ['mean_normalized_height'], volume)\n",
    "visualize_pc(targets, col='mean_normalized_height', clabel='Mean Normalized Height', pointsize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`laserchicken` also supports self defined feature extractor. Below is an example of a self-defined feature extractor which computes the ratio of points within the volumn with height >10m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserchicken import register_new_feature_extractor\n",
    "from laserchicken.feature_extractor.band_ratio_feature_extractor import BandRatioFeatureExtractor\n",
    "register_new_feature_extractor(BandRatioFeatureExtractor(10,None,data_key='normalized_height'))\n",
    "\n",
    "volume = build_volume(\"cell\", side_length=resolution)\n",
    "neighborhoods = compute_neighborhoods(pc_non_ground, targets, volume)\n",
    "compute_features(pc_non_ground, neighborhoods, targets, ['band_ratio_10<normalized_height'], volume)\n",
    "visualize_pc(targets, col='band_ratio_10<normalized_height', clabel='Ratio Normalized height >10m', pointsize=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be exported to the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from laserchicken import export\n",
    "export(targets, 'my_output.laz')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a76de9213e5186f2b22a8aaf0ed98a74a160e66179f4e52adab6dffa325934ee"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('l_tutorial': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
